{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Import package\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import time\n",
    "import pandas\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Read Image\n",
    "\"\"\"\n",
    "def readfile(path, label=None, imgRow=256, imgCol=256, datasize=10000):\n",
    "    # label 是 csv file 在 ./ 下的名稱，有提供則回傳 y\n",
    "    image_dir = sorted(os.listdir(path))\n",
    "    i = 0\n",
    "    count = 0\n",
    "    eachFolder = datasize // 1000 #so each folder 10 or 100 images\n",
    "    x = np.zeros((datasize, imgRow, imgCol, 1), dtype=np.uint8)\n",
    "    y = np.zeros((datasize, imgRow, imgCol, 2), dtype=np.uint8)\n",
    "    \n",
    "    \n",
    "    for folders in tqdm(image_dir):\n",
    "        imgPath = os.path.join(path, folders)\n",
    "        for file in os.listdir(imgPath):\n",
    "            img = cv2.imread(os.path.join(imgPath, file))\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "            #return\n",
    "            \n",
    "            # 0≤L≤100 , −127≤a≤127, −127≤b≤127\n",
    "            # 8-bit images: L←L∗255/100,a←a+128,b←b+128\n",
    "            img = cv2.resize(img,(imgCol, imgRow))\n",
    "            lab_image = cv2.cvtColor(img, cv2.COLOR_BGR2LAB) \n",
    "            l_channel, a_channel, b_channel = cv2.split(lab_image)\n",
    "            x[i, :, :, 0] = l_channel # (x, y)\n",
    "            y[i, :, :, 0] = a_channel\n",
    "            y[i, :, :, 1] = b_channel\n",
    "            i += 1\n",
    "            count += 1\n",
    "            if(count == eachFolder):\n",
    "                count = 0\n",
    "                break\n",
    "    return x, y\n",
    "    \n",
    "def valAndTest(path, label=None, imgRow=256, imgCol=256, datasize=2000):\n",
    "    # label 是 csv file 在 ./ 下的名稱，有提供則回傳 y\n",
    "    image_dir = sorted(os.listdir(path))\n",
    "    i = 0\n",
    "    j = 0\n",
    "    count = 0\n",
    "    eachFolder = datasize // 1000 #so each folder 10 or 100 images\n",
    "    xVal = np.zeros((datasize, imgRow, imgCol, 1), dtype=np.uint8)\n",
    "    yVal = np.zeros((datasize, imgRow, imgCol, 2), dtype=np.uint8)\n",
    "    xTest= np.zeros((datasize, imgRow, imgCol, 1), dtype=np.uint8)\n",
    "    yTest= np.zeros((datasize, imgRow, imgCol, 2), dtype=np.uint8)\n",
    "    \n",
    "    for file in image_dir:\n",
    "        img = cv2.imread(os.path.join(path, file))\n",
    "        img = cv2.resize(img,(imgCol, imgRow))\n",
    "        lab_image = cv2.cvtColor(img, cv2.COLOR_BGR2LAB) \n",
    "        l_channel, a_channel, b_channel = cv2.split(lab_image)\n",
    "        \n",
    "        if(count < datasize): # val\n",
    "            xVal[i, :, :, 0]    = l_channel\n",
    "            yVal[i, :, :, 0] = a_channel\n",
    "            yVal[i, :, :, 1] = b_channel\n",
    "            i += 1\n",
    "        else: # test\n",
    "            xTest[j, :, :, 0]    = l_channel\n",
    "            yTest[j, :, :, 0] = a_channel\n",
    "            yTest[j, :, :, 1] = b_channel\n",
    "            j += 1\n",
    "        count += 1\n",
    "        \n",
    "        if(count == datasize*2):\n",
    "            break\n",
    "    \n",
    "            \n",
    "    return xVal, yVal, xTest, yTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#分別將 training set、validation set、testing set 用 readfile 函式讀進來\n",
    "workspace_dir = 'D:\\Downloads\\ILSVRC\\Data\\CLS-LOC'\n",
    "print(\"Reading data\")\n",
    "train_x, train_y = readfile(os.path.join(workspace_dir, \"train\"), \"train\", imgRow=256, imgCol=256, datasize=100000)\n",
    "print(\"Size of training data = {}\".format(len(train_x)))\n",
    "\n",
    "val_x, val_y, test_x, test_y = valAndTest(os.path.join(workspace_dir, \"val\"), \"dev\", imgRow=256, imgCol=256, datasize=5000)\n",
    "print(\"Size of validation data = {}\".format(len(val_x)))\n",
    "print(\"Size of testing data = {}\".format(len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = train_x[101]\n",
    "realAB = train_y[101]\n",
    "realImg = (np.concatenate((L, realAB), axis=2)).astype(np.uint8)\n",
    "# opencv 用 datatype 判斷圖片\n",
    "realImg = cv2.cvtColor(realImg, cv2.COLOR_LAB2RGB)\n",
    "plt.imshow(realImg)\n",
    "plt.show()\n",
    "\n",
    "L = train_x[99000]\n",
    "realAB = train_y[99000]\n",
    "realImg = (np.concatenate((L, realAB), axis=2)).astype(np.uint8)\n",
    "# opencv 用 datatype 判斷圖片\n",
    "realImg = cv2.cvtColor(realImg, cv2.COLOR_LAB2RGB)\n",
    "plt.imshow(realImg)\n",
    "plt.show()\n",
    "\n",
    "L = val_x[4999]\n",
    "realAB = val_y[4999]\n",
    "realImg = (np.concatenate((L, realAB), axis=2)).astype(np.uint8)\n",
    "# opencv 用 datatype 判斷圖片\n",
    "realImg = cv2.cvtColor(realImg, cv2.COLOR_LAB2RGB)\n",
    "plt.imshow(realImg)\n",
    "plt.show()\n",
    "\n",
    "L = test_x[4999]\n",
    "realAB = test_y[4999]\n",
    "realImg = (np.concatenate((L, realAB), axis=2)).astype(np.uint8)\n",
    "# opencv 用 datatype 判斷圖片\n",
    "realImg = cv2.cvtColor(realImg, cv2.COLOR_LAB2RGB)\n",
    "plt.imshow(realImg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "\n",
    "fineSize = 176 # 因為 /4 = 44\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def transform(self, image, mask):\n",
    "        #transforms.ToPILImage(),\n",
    "        toPIL = transforms.ToPILImage()\n",
    "        image = toPIL(image)\n",
    "        mask = toPIL(mask)\n",
    "        \n",
    "        # Resize\n",
    "        resize = transforms.Resize(size=(fineSize, fineSize))\n",
    "        image = resize(image)\n",
    "        mask = resize(mask)\n",
    "\n",
    "        # Random crop\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(\n",
    "            image, output_size=(fineSize, fineSize))\n",
    "        image = TF.crop(image, i, j, h, w)\n",
    "        mask = TF.crop(mask, i, j, h, w)\n",
    "\n",
    "        # Random horizontal flipping\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask = TF.hflip(mask)\n",
    "\n",
    "        # Random vertical flipping\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.vflip(image)\n",
    "            mask = TF.vflip(mask)\n",
    "\n",
    "        # Transform to tensor\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X, Y = self.transform(self.x[index], self.y[index])\n",
    "        return X, Y\n",
    "\n",
    "\"\"\"\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomChoice([transforms.RandomResizedCrop(fineSize, interpolation=1),\n",
    "                            transforms.RandomResizedCrop(fineSize, interpolation=2),\n",
    "                            transforms.RandomResizedCrop(fineSize, interpolation=3)]),\n",
    "    transforms.RandomHorizontalFlip(), #隨機將圖片水平翻轉\n",
    "    transforms.RandomVerticalFlip(), #隨機將圖片垂直翻轉\n",
    "    transforms.ToTensor(), #將圖片轉成 Tensor，並把數值normalize到[0,1](data normalization)\n",
    "])\n",
    "#testing & val 時不需做 data augmentation\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomChoice([transforms.RandomResizedCrop(fineSize, interpolation=1),\n",
    "                            transforms.RandomResizedCrop(fineSize, interpolation=2),\n",
    "                            transforms.RandomResizedCrop(fineSize, interpolation=3)]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\"\"\"\n",
    "#會有 X 與 Y transform 不一致的問題\n",
    "#https://discuss.pytorch.org/t/torchvision-transfors-how-to-perform-identical-transform-on-both-image-and-target/10606/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ImgDataset(train_x, train_y)\n",
    "val_set = ImgDataset(val_x, val_y)\n",
    "\n",
    "batch_size = 24\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "#num_workers= ? #如果 load data 特別處理，可能有 preprocessing。幫助平行化\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False) #windows 只能 run 0\n",
    "#https://github.com/pytorch/pytorch/issues/2341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Model\n",
    "\"\"\"\n",
    "# input 維度 [3, 176, 176]\n",
    "# nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "# nn.MaxPool2d(kernel_size, stride, padding)\n",
    "# nn.ReLU(inplace=False) #true 可以些微降低記憶體使用量 (如果不會造成問題的話)\n",
    "# nn.LeakyReLU\n",
    "# nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros')\n",
    "# nn.BatchNorm2d(channels)\n",
    "# nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None)\n",
    "\n",
    "# Resnet, ResNeXt\n",
    "#https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=True, dilation=dilation)\n",
    "    #In a large model, removing the bias inputs makes very little difference \n",
    "    #https://stackoverflow.com/questions/51959507/does-bias-in-the-convolutional-layer-really-make-a-difference-to-the-test-accura\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=True)\n",
    "    \n",
    "    \n",
    "  \n",
    "\"\"\"\n",
    "    (0): BasicBlock(\n",
    "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "    ...\n",
    "    之後需要增加 channel 的時候再對 input 做 1x1 conv \n",
    "    (0): BasicBlock(\n",
    "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (downsample): Sequential(\n",
    "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      )\n",
    "    )\n",
    "\"\"\"\n",
    "# pre-activation (resnet v2)\n",
    "# ResnetBlock(64, 128, downsample=True) -> 128\n",
    "# ResnetBlock(128, 128, isThree=True) -> 128\n",
    "class ResnetBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, norm_layer=None, downsample=False, isThree=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "            \n",
    "        self.bn1 = norm_layer(inplanes) #64\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride) #64 -> 128\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.conv2 = conv3x3(planes, planes) #128 -> 128\n",
    "        self.bn3 = norm_layer(planes)\n",
    "        self.conv3 = conv3x3(planes, planes) \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.down = conv1x1(inplanes, planes) #64->128\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        self.isThree = isThree\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        if(self.isThree):\n",
    "            out = self.bn3(out)\n",
    "            out = self.relu(out)\n",
    "            out = self.conv3(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            identity = self.down(x)\n",
    "\n",
    "        out += identity\n",
    "\n",
    "        return out\n",
    "\n",
    "\"\"\"\n",
    "(0)Bottleneck(\n",
    "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
    "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    "    (downsample): Sequential(\n",
    "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    ")\n",
    "之後正常\n",
    "(1): Bottleneck(\n",
    "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
    "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (relu): ReLU(inplace=True)\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "#ResNextBasicBlock(64, downsample=True) -> 128\n",
    "#ResNextBasicBlock(128) -> 128\n",
    "class ResNextBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes=0, stride=1, groups=32, dilation=1, norm_layer=None, downsample=False):\n",
    "        super(ResNextBasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        \n",
    "        width = inplanes\n",
    "        \n",
    "        if downsample:\n",
    "            width *= 2\n",
    "        \n",
    "        self.conv1 = conv3x3(inplanes, width*2, groups=groups) #64 -> 256\n",
    "        self.bn1 = norm_layer(width*2)\n",
    "        self.conv2 = conv3x3(width*2, width) #256->128\n",
    "        self.bn2 = norm_layer(width)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.down = conv1x1(inplanes, width) #64->128\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            identity = self.down(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "#ResNextBlock(64, 64, downsample=True) -> 128\n",
    "#ResNextBlock(128, 64) -> 128\n",
    "class ResNextBlock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, groups=32, dilation=1, norm_layer=None, downsample=False):\n",
    "        super(ResNextBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = planes\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width) #64->64\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation) #64->64\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, width * 2) #64->128\n",
    "        self.bn3 = norm_layer(width * 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.down = conv1x1(inplanes, width * 2) #64->128\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            identity = self.down(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resNeXtUnet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, classification=True):\n",
    "        super(resNeXtUnet, self).__init__()\n",
    "        self.classification = classification\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            conv3x3(in_channels, 64), # 4 -> raw 1 channel + rgb userinput 3 channels\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv3x3(64, 64),\n",
    "        )\n",
    "        \n",
    "        #downsampling\n",
    "        self.conv2 = ResNextBasicBlock(64, 128, downsample=True)\n",
    "        \n",
    "        #downsampling\n",
    "        #ResNextBasicBlock(64, downsample=True) -> 128\n",
    "        #ResNextBasicBlock(128) -> 128\n",
    "        self.conv3 = ResNextBlock(128, 128, downsample=True)\n",
    "        \n",
    "         #downsampling\n",
    "        self.conv4 = ResNextBlock(256, 256, downsample=True)\n",
    "        \n",
    "        self.conv5 = ResNextBlock(512, 256)\n",
    "        \n",
    "        self.conv6 = ResNextBlock(512, 256)\n",
    "        \n",
    "        self.conv7 = ResNextBlock(512, 256)\n",
    "        \n",
    "        #upsampling\n",
    "        self.up8 = nn.Sequential(\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "        )\n",
    "        \n",
    "        self.conv8 = ResNextBlock(256, 128)\n",
    "        \n",
    "        #upsampling\n",
    "        self.up9 = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "        )\n",
    "        \n",
    "        self.conv9 = ResNextBasicBlock(128)\n",
    "        \n",
    "        #upsampling\n",
    "        self.up10 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "        )\n",
    "        \n",
    "        self.conv1to10 = nn.Sequential(\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv3x3(64, 128)\n",
    "        )\n",
    "        self.conv10 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv3x3(128, 128)\n",
    "        )\n",
    "        \n",
    "        # classification output\n",
    "        self.model_class= nn.Conv2d(256, 529, kernel_size=1, padding=0, dilation=1, stride=1, bias=True)\n",
    "        \n",
    "        # regression output\n",
    "        self.model_out = nn.Sequential(\n",
    "            nn.Conv2d(128, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=True), #128 -> 2\n",
    "            nn.Sigmoid(), # 0~1\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 1, 10 not touch\n",
    "        conv1_2 = self.conv1(x)\n",
    "        conv2_2 = self.conv2(conv1_2[:,:,::2,::2])\n",
    "        conv3_3 = self.conv3(conv2_2[:,:,::2,::2])\n",
    "        \n",
    "        conv4_3 = self.conv4(conv3_3[:,:,::2,::2])\n",
    "        conv5_3 = self.conv5(conv4_3)\n",
    "        conv6_3 = self.conv6(conv5_3)\n",
    "        conv7_3 = self.conv7(conv6_3)\n",
    "        \n",
    "        #前面的都 res 了\n",
    "        conv8_up = self.up8(conv7_3)\n",
    "        conv8_3 = self.conv8(conv8_up + conv3_3) + (conv8_up + conv3_3)\n",
    "\n",
    "        if(self.classification):\n",
    "            out_class = self.model_class(conv8_3)\n",
    "\n",
    "            conv9_up = self.up9(conv8_3.detach())\n",
    "            conv9_3 = self.conv9(conv9_up + conv2_2.detach()) + (conv9_up + conv2_2.detach())\n",
    "\n",
    "            conv10_up = self.up10(conv9_3) + self.conv1to10(conv1_2.detach())\n",
    "            conv10_2 = self.conv10(conv10_up)\n",
    "            out_reg = self.model_out(conv10_2)\n",
    "        else:\n",
    "            out_class = self.model_class(conv8_3.detach())\n",
    "\n",
    "            conv9_up = self.up9(conv8_3)\n",
    "            conv9_3 = self.conv9(conv9_up + conv2_2) + (conv9_up + conv2_2)\n",
    "\n",
    "            conv10_up = self.up10(conv9_3) + self.conv1to10(conv1_2)\n",
    "            conv10_2 = self.conv10(conv10_up)\n",
    "            out_reg = self.model_out(conv10_2)\n",
    "\n",
    "        return (out_class, out_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 176, 176]             640\n",
      "       BatchNorm2d-2         [-1, 64, 176, 176]             128\n",
      "              ReLU-3         [-1, 64, 176, 176]               0\n",
      "            Conv2d-4         [-1, 64, 176, 176]          36,928\n",
      "            Conv2d-5          [-1, 256, 88, 88]           4,864\n",
      "       BatchNorm2d-6          [-1, 256, 88, 88]             512\n",
      "              ReLU-7          [-1, 256, 88, 88]               0\n",
      "            Conv2d-8          [-1, 128, 88, 88]         295,040\n",
      "       BatchNorm2d-9          [-1, 128, 88, 88]             256\n",
      "             ReLU-10          [-1, 128, 88, 88]               0\n",
      "           Conv2d-11          [-1, 128, 88, 88]           8,320\n",
      "             ReLU-12          [-1, 128, 88, 88]               0\n",
      "ResNextBasicBlock-13          [-1, 128, 88, 88]               0\n",
      "           Conv2d-14          [-1, 128, 44, 44]          16,512\n",
      "      BatchNorm2d-15          [-1, 128, 44, 44]             256\n",
      "             ReLU-16          [-1, 128, 44, 44]               0\n",
      "           Conv2d-17          [-1, 128, 44, 44]           4,736\n",
      "      BatchNorm2d-18          [-1, 128, 44, 44]             256\n",
      "             ReLU-19          [-1, 128, 44, 44]               0\n",
      "           Conv2d-20          [-1, 256, 44, 44]          33,024\n",
      "      BatchNorm2d-21          [-1, 256, 44, 44]             512\n",
      "           Conv2d-22          [-1, 256, 44, 44]          33,024\n",
      "             ReLU-23          [-1, 256, 44, 44]               0\n",
      "     ResNextBlock-24          [-1, 256, 44, 44]               0\n",
      "           Conv2d-25          [-1, 256, 22, 22]          65,792\n",
      "      BatchNorm2d-26          [-1, 256, 22, 22]             512\n",
      "             ReLU-27          [-1, 256, 22, 22]               0\n",
      "           Conv2d-28          [-1, 256, 22, 22]          18,688\n",
      "      BatchNorm2d-29          [-1, 256, 22, 22]             512\n",
      "             ReLU-30          [-1, 256, 22, 22]               0\n",
      "           Conv2d-31          [-1, 512, 22, 22]         131,584\n",
      "      BatchNorm2d-32          [-1, 512, 22, 22]           1,024\n",
      "           Conv2d-33          [-1, 512, 22, 22]         131,584\n",
      "             ReLU-34          [-1, 512, 22, 22]               0\n",
      "     ResNextBlock-35          [-1, 512, 22, 22]               0\n",
      "           Conv2d-36          [-1, 256, 22, 22]         131,328\n",
      "      BatchNorm2d-37          [-1, 256, 22, 22]             512\n",
      "             ReLU-38          [-1, 256, 22, 22]               0\n",
      "           Conv2d-39          [-1, 256, 22, 22]          18,688\n",
      "      BatchNorm2d-40          [-1, 256, 22, 22]             512\n",
      "             ReLU-41          [-1, 256, 22, 22]               0\n",
      "           Conv2d-42          [-1, 512, 22, 22]         131,584\n",
      "      BatchNorm2d-43          [-1, 512, 22, 22]           1,024\n",
      "             ReLU-44          [-1, 512, 22, 22]               0\n",
      "     ResNextBlock-45          [-1, 512, 22, 22]               0\n",
      "           Conv2d-46          [-1, 256, 22, 22]         131,328\n",
      "      BatchNorm2d-47          [-1, 256, 22, 22]             512\n",
      "             ReLU-48          [-1, 256, 22, 22]               0\n",
      "           Conv2d-49          [-1, 256, 22, 22]          18,688\n",
      "      BatchNorm2d-50          [-1, 256, 22, 22]             512\n",
      "             ReLU-51          [-1, 256, 22, 22]               0\n",
      "           Conv2d-52          [-1, 512, 22, 22]         131,584\n",
      "      BatchNorm2d-53          [-1, 512, 22, 22]           1,024\n",
      "             ReLU-54          [-1, 512, 22, 22]               0\n",
      "     ResNextBlock-55          [-1, 512, 22, 22]               0\n",
      "           Conv2d-56          [-1, 256, 22, 22]         131,328\n",
      "      BatchNorm2d-57          [-1, 256, 22, 22]             512\n",
      "             ReLU-58          [-1, 256, 22, 22]               0\n",
      "           Conv2d-59          [-1, 256, 22, 22]          18,688\n",
      "      BatchNorm2d-60          [-1, 256, 22, 22]             512\n",
      "             ReLU-61          [-1, 256, 22, 22]               0\n",
      "           Conv2d-62          [-1, 512, 22, 22]         131,584\n",
      "      BatchNorm2d-63          [-1, 512, 22, 22]           1,024\n",
      "             ReLU-64          [-1, 512, 22, 22]               0\n",
      "     ResNextBlock-65          [-1, 512, 22, 22]               0\n",
      "      BatchNorm2d-66          [-1, 512, 22, 22]           1,024\n",
      "             ReLU-67          [-1, 512, 22, 22]               0\n",
      "  ConvTranspose2d-68          [-1, 256, 44, 44]       2,097,408\n",
      "           Conv2d-69          [-1, 128, 44, 44]          32,896\n",
      "      BatchNorm2d-70          [-1, 128, 44, 44]             256\n",
      "             ReLU-71          [-1, 128, 44, 44]               0\n",
      "           Conv2d-72          [-1, 128, 44, 44]           4,736\n",
      "      BatchNorm2d-73          [-1, 128, 44, 44]             256\n",
      "             ReLU-74          [-1, 128, 44, 44]               0\n",
      "           Conv2d-75          [-1, 256, 44, 44]          33,024\n",
      "      BatchNorm2d-76          [-1, 256, 44, 44]             512\n",
      "             ReLU-77          [-1, 256, 44, 44]               0\n",
      "     ResNextBlock-78          [-1, 256, 44, 44]               0\n",
      "           Conv2d-79          [-1, 529, 44, 44]         135,953\n",
      "      BatchNorm2d-80          [-1, 256, 44, 44]             512\n",
      "             ReLU-81          [-1, 256, 44, 44]               0\n",
      "  ConvTranspose2d-82          [-1, 128, 88, 88]         524,416\n",
      "           Conv2d-83          [-1, 256, 88, 88]           9,472\n",
      "      BatchNorm2d-84          [-1, 256, 88, 88]             512\n",
      "             ReLU-85          [-1, 256, 88, 88]               0\n",
      "           Conv2d-86          [-1, 128, 88, 88]         295,040\n",
      "      BatchNorm2d-87          [-1, 128, 88, 88]             256\n",
      "             ReLU-88          [-1, 128, 88, 88]               0\n",
      "             ReLU-89          [-1, 128, 88, 88]               0\n",
      "ResNextBasicBlock-90          [-1, 128, 88, 88]               0\n",
      "      BatchNorm2d-91          [-1, 128, 88, 88]             256\n",
      "             ReLU-92          [-1, 128, 88, 88]               0\n",
      "  ConvTranspose2d-93        [-1, 128, 176, 176]         262,272\n",
      "      BatchNorm2d-94         [-1, 64, 176, 176]             128\n",
      "             ReLU-95         [-1, 64, 176, 176]               0\n",
      "           Conv2d-96        [-1, 128, 176, 176]          73,856\n",
      "      BatchNorm2d-97        [-1, 128, 176, 176]             256\n",
      "             ReLU-98        [-1, 128, 176, 176]               0\n",
      "           Conv2d-99        [-1, 128, 176, 176]         147,584\n",
      "          Conv2d-100          [-1, 2, 176, 176]             258\n",
      "         Sigmoid-101          [-1, 2, 176, 176]               0\n",
      "================================================================\n",
      "Total params: 5,256,531\n",
      "Trainable params: 5,256,531\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 574.06\n",
      "Params size (MB): 20.05\n",
      "Estimated Total Size (MB): 594.23\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = resNeXtUnet(in_channels=1, out_channels=2).cuda()\n",
    "print( summary(model, (1, 176, 176)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resUnet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, classification=True):\n",
    "        super(resUnet, self).__init__()\n",
    "        self.classification = classification\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            conv3x3(in_channels, 64), # 4 -> raw 1 channel + rgb userinput 3 channels\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv3x3(64, 64),\n",
    "        )\n",
    "        \n",
    "        #downsampling\n",
    "        self.conv2 = ResnetBlock(64, 128, downsample=True)\n",
    "        \n",
    "        #downsampling\n",
    "        self.conv3 = ResnetBlock(128, 256, downsample=True, isThree=True)\n",
    "        \n",
    "         #downsampling\n",
    "        self.conv4 = ResnetBlock(256, 512, downsample=True, isThree=True)\n",
    "        \n",
    "        self.conv5 = ResnetBlock(512, 512, isThree=True)\n",
    "        \n",
    "        self.conv6 = ResnetBlock(512, 512, isThree=True)\n",
    "        \n",
    "        self.conv7 = ResnetBlock(512, 512, isThree=True)\n",
    "        \n",
    "        #upsampling\n",
    "        self.up8 = nn.Sequential(\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "        )\n",
    "        \n",
    "        self.conv3to8 = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv3x3(256, 256)\n",
    "        )\n",
    "        self.conv8 = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv3x3(256, 256),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv3x3(256, 256),\n",
    "        )\n",
    "        \n",
    "        #upsampling\n",
    "        self.up9 = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "        )\n",
    "        \n",
    "        self.conv2to9 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv3x3(128, 128)\n",
    "        )\n",
    "        self.conv9 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv3x3(128, 128),\n",
    "        )\n",
    "        \n",
    "        #upsampling\n",
    "        self.up10 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1, bias=True)\n",
    "        )\n",
    "        \n",
    "        self.conv1to10 = nn.Sequential(\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv3x3(64, 128)\n",
    "        )\n",
    "        self.conv10 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv3x3(128, 128),\n",
    "            nn.LeakyReLU(negative_slope=.2),\n",
    "        )\n",
    "        \n",
    "        # classification output\n",
    "        self.model_class= nn.Conv2d(256, 529, kernel_size=1, padding=0, dilation=1, stride=1, bias=True)\n",
    "        \n",
    "        # regression output\n",
    "        self.model_out = nn.Sequential(\n",
    "            nn.Conv2d(128, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=True), #128 -> 2\n",
    "            nn.Sigmoid(), # 0~1\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 1, 10 not touch\n",
    "        conv1_2 = self.conv1(x)\n",
    "        conv2_2 = self.conv2(conv1_2[:,:,::2,::2])\n",
    "        conv3_3 = self.conv3(conv2_2[:,:,::2,::2])\n",
    "        \n",
    "        conv4_3 = self.conv4(conv3_3[:,:,::2,::2])\n",
    "        conv5_3 = self.conv5(conv4_3)\n",
    "        conv6_3 = self.conv6(conv5_3)\n",
    "        conv7_3 = self.conv7(conv6_3)\n",
    "        \n",
    "        #前面的都 res 了\n",
    "        conv8_up = self.up8(conv7_3) + self.conv3to8(conv3_3)\n",
    "        conv8_3 = self.conv8(conv8_up) + conv8_up\n",
    "\n",
    "        if(self.classification):\n",
    "            out_class = self.model_class(conv8_3)\n",
    "\n",
    "            conv9_up = self.up9(conv8_3.detach()) + self.conv2to9(conv2_2.detach())\n",
    "            conv9_3 = self.conv9(conv9_up) + conv9_up\n",
    "\n",
    "            conv10_up = self.up10(conv9_3) + self.conv1to10(conv1_2.detach())\n",
    "            conv10_2 = self.conv10(conv10_up)\n",
    "            out_reg = self.model_out(conv10_2)\n",
    "        else:\n",
    "            out_class = self.model_class(conv8_3.detach())\n",
    "\n",
    "            conv9_up = self.up9(conv8_3) + self.conv2to9(conv2_2)\n",
    "            conv9_3 = self.conv9(conv9_up) + conv9_up\n",
    "\n",
    "            conv10_up = self.up10(conv9_3) + self.conv1to10(conv1_2)\n",
    "            conv10_2 = self.conv10(conv10_up)\n",
    "            out_reg = self.model_out(conv10_2)\n",
    "\n",
    "        return (out_class, out_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Utility\n",
    "\"\"\"\n",
    "def calculate_psnr_np(img1, img2): # for uint8 image\n",
    "    SE_map = (1.*img1-img2)**2\n",
    "    cur_MSE = np.mean(SE_map)\n",
    "    return 20*np.log10(255./np.sqrt(cur_MSE))\n",
    "\n",
    "\n",
    "def calculate_psnr_torch(img1, img2):\n",
    "    SE_map = (1.*img1-img2)**2\n",
    "    cur_MSE = torch.mean(SE_map)\n",
    "    return 20*torch.log10(1./torch.sqrt(cur_MSE))\n",
    "\n",
    "# the ab space is divided into 10 × 10 bins, Q = 313\n",
    "def encode_ab_ind(data_ab, ab_norm=220, ab_quant=10):\n",
    "    # Encode ab value into an index\n",
    "    # INPUTS\n",
    "    #   data_ab   Nx2xHxW \\in [0,1]\n",
    "    # OUTPUTS\n",
    "    #   data_q    Nx1xHxW \\in [0,Q)\n",
    "    \n",
    "    #no need ab max, because origin [-1, 1] need shift to [0,~]\n",
    "    \n",
    "    #變回 -110~110 -> 0~220 -> 0~22 (共 23) 所以才有 23*23 = 529\n",
    "    #A = 2*110/10 + 1 = 23\n",
    "    \n",
    "    data_ab_rs = torch.round((data_ab*ab_norm)/ab_quant) # normalized bin number\n",
    "    #opt.A = 2 * opt.ab_max / opt.ab_quant + 1\n",
    "    data_q = data_ab_rs[:,[0],:,:]* (ab_norm / ab_quant + 1)  + data_ab_rs[:,[1],:,:]\n",
    "    return data_q\n",
    "\n",
    "\n",
    "def decode_ind_ab(data_q, opt):\n",
    "    # Decode index into ab value\n",
    "    # INPUTS\n",
    "    #   data_q      Nx1xHxW \\in [0,Q)\n",
    "    # OUTPUTS\n",
    "    #   data_ab     Nx2xHxW \\in [-1,1]\n",
    "\n",
    "    data_a = data_q/opt.A\n",
    "    data_b = data_q - data_a*opt.A\n",
    "    data_ab = torch.cat((data_a,data_b),dim=1)\n",
    "\n",
    "    if(data_q.is_cuda):\n",
    "        type_out = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        type_out = torch.FloatTensor\n",
    "    data_ab = ((data_ab.type(type_out)*opt.ab_quant) - opt.ab_max)/opt.ab_norm\n",
    "\n",
    "    return data_ab\n",
    "\n",
    "\n",
    "## Loss\n",
    "# 自己定義 loss \n",
    "# https://discuss.pytorch.org/t/custom-loss-functions/29387\n",
    "# loss = nn.CrossEntropyLoss() # 如果是 classification task\n",
    "def my_loss(output, target):\n",
    "    mask = torch.zeros_like(output)\n",
    "    mann = torch.abs(output-target)\n",
    "    eucl = .5 * (mann**2)\n",
    "    mask[...] = mann < self.delta # < delta 的會 = 1\n",
    "\n",
    "    # loss = eucl*mask + self.delta*(mann-.5*self.delta)*(1-mask)\n",
    "    # 前半 < delta，後半 > delta\n",
    "    loss = eucl*mask/self.delta + (mann-.5*self.delta)*(1-mask)\n",
    "    return torch.sum(loss,dim=1,keepdim=True)\n",
    "\n",
    "\n",
    "class HuberLoss(nn.Module):\n",
    "    def __init__(self, delta=.01):\n",
    "        super(HuberLoss, self).__init__()\n",
    "        self.delta=delta\n",
    "\n",
    "    def __call__(self, in0, in1):\n",
    "        mask = torch.zeros_like(in0)\n",
    "        mann = torch.abs(in0-in1)\n",
    "        eucl = .5 * (mann**2)\n",
    "        mask[...] = mann < self.delta # < delta 的會 = 1\n",
    "\n",
    "        # loss = eucl*mask + self.delta*(mann-.5*self.delta)*(1-mask)\n",
    "        # 前半 < delta，後半 > delta\n",
    "        loss = eucl*mask/self.delta + (mann-.5*self.delta)*(1-mask)\n",
    "        return torch.sum(loss,dim=1,keepdim=True)\n",
    "\"\"\"\n",
    "class L1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L1Loss, self).__init__()\n",
    "\n",
    "    def __call__(self, in0, in1):\n",
    "        return torch.sum(torch.abs(in0-in1),dim=1,keepdim=True)\n",
    "\"\"\"\n",
    "    \n",
    "#loss = nn.SmoothL1Loss(size_average=None, reduce=None, reduction='sum')\n",
    "lossL1 = nn.L1Loss(size_average=None, reduce=None, reduction='mean') #or 'sum'\n",
    "lossCE = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Training\n",
    "\"\"\"\n",
    "#training 時做 data augmentation\n",
    "# 官方說明\n",
    "# https://pytorch.org/docs/stable/torchvision/transforms.html#module-torchvision.transforms.functional\n",
    "# 中文說明(有解釋)\n",
    "# https://wizardforcel.gitbooks.io/learn-dl-with-pytorch-liaoxingyu/4.7.1.html\n",
    "\n",
    "#model = Classifier().cuda()\n",
    "\n",
    "localPath = \"./stage1/\"\n",
    "\n",
    "## Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "# optimizer 必須要吃到 model 的參數\n",
    "#據說 SGD+momentum test 表現好\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epoch = 100\n",
    "best_val_loss = 1e+9\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    iter_data_time = time.time()\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    model.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
    "    for i, data in enumerate(tqdm(train_loader)):\n",
    "        iter_start_time = time.time()\n",
    "        # time to load data\n",
    "        t_data = iter_start_time - iter_data_time\n",
    "\n",
    "        # 確保歸零，不然會累積\n",
    "        optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
    "        pred_class, train_pred = model(data[0].cuda()) # 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
    "        #print(train_pred.size(), data[1].size())\n",
    "        \n",
    "        real_B_enc = encode_ab_ind(data[1][:, :, ::4, ::4])\n",
    "        \n",
    "        # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
    "        loss_L1_reg = lossL1(train_pred.type(torch.cuda.FloatTensor), data[1].type(torch.cuda.FloatTensor).cuda())\n",
    "        loss_CE = lossCE(pred_class.type(torch.cuda.FloatTensor), real_B_enc[:, 0, :, :].type(torch.cuda.LongTensor).cuda())\n",
    "        batch_loss = loss_L1_reg + loss_CE\n",
    "        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
    "        optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
    "\n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            pred_class, val_pred = model(data[0].cuda())\n",
    "            #batch_loss = loss(val_pred, data[1].cuda())\n",
    "            real_B_enc = encode_ab_ind(data[1][:, :, ::4, ::4])\n",
    "            loss_L1_reg = lossL1(val_pred.type(torch.cuda.FloatTensor), data[1].type(torch.cuda.FloatTensor).cuda())\n",
    "            loss_CE = lossCE(pred_class.type(torch.cuda.FloatTensor), real_B_enc[:, 0, :, :].type(torch.cuda.LongTensor).cuda())\n",
    "            batch_loss = loss_L1_reg + loss_CE\n",
    "            if(i == 1):\n",
    "                L = data[0][6].cpu().numpy().transpose(1, 2, 0)\n",
    "                realAB = data[1][6].cpu().numpy().transpose(1, 2, 0)\n",
    "                predAB = val_pred[6].cpu().numpy().transpose(1, 2, 0)\n",
    "                realImg = (np.concatenate((L, realAB), axis=2) * 255).astype(np.uint8)\n",
    "                fakeImg = (np.concatenate((L, predAB), axis=2) * 255).astype(np.uint8)\n",
    "                # opencv 用 datatype 判斷圖片\n",
    "                realImg = cv2.cvtColor(realImg, cv2.COLOR_LAB2BGR)\n",
    "                fakeImg = cv2.cvtColor(fakeImg, cv2.COLOR_LAB2BGR) \n",
    "                #print(realImg)\n",
    "                #plt.imshow(realImg)\n",
    "                #plt.show()\n",
    "                cv2.imwrite(localPath + str(epoch + 1) + \"_real\" + \".png\"  , realImg)\n",
    "                cv2.imwrite(localPath + str(epoch + 1) + \"_fake\" + \".png\"  , fakeImg)\n",
    "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "            val_loss += batch_loss.item()\n",
    "        \n",
    "        # 只 save parameters (建議的方式)\n",
    "        torch.save(model.state_dict(), localPath + str(epoch + 1) +  \"_stage3_res_model\")\n",
    "        \n",
    "        #if val_loss < best_val_loss:\n",
    "        #    best_val_loss = val_loss\n",
    "        #    torch.save(model, \"best_model\")\n",
    "        #將結果 print 出來\n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f | time to load: %2.2f' % \\\n",
    "            (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
    "             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__(), t_data))\n",
    "        \n",
    "        train_loss_history.append(train_loss/train_set.__len__())\n",
    "        val_loss_history.append(val_loss/val_set.__len__())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss_history)), train_loss_history)\n",
    "plt.plot(range(len(val_loss_history)), val_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(localPath + \"res_stage2_train_loss\", np.array(train_loss_history))\n",
    "np.save(localPath + \"res_stage2_val_loss\", np.array(val_loss_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train regression\n",
    "PATH = \"./100_res_model\"\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "niter = 15\n",
    "model = resUnet(in_channels=1, out_channels=2, classification=False).cuda()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    iter_data_time = time.time()\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    model.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
    "    for i, data in enumerate(tqdm(train_loader)):\n",
    "        iter_start_time = time.time()\n",
    "        # time to load data\n",
    "        t_data = iter_start_time - iter_data_time\n",
    "\n",
    "        # 確保歸零，不然會累積\n",
    "        optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
    "        pred_class, train_pred = model(data[0].cuda()) # 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
    "        #print(train_pred.size(), data[1].size())\n",
    "        \n",
    "        real_B_enc = encode_ab_ind(data[1][:, :, ::4, ::4])\n",
    "        \n",
    "        # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
    "        loss_L1_reg = lossL1(train_pred.type(torch.cuda.FloatTensor), data[1].type(torch.cuda.FloatTensor).cuda())\n",
    "        loss_CE = lossCE(pred_class.type(torch.cuda.FloatTensor), real_B_enc[:, 0, :, :].type(torch.cuda.LongTensor).cuda())\n",
    "        # 自動 one-hot encoding\n",
    "        batch_loss = loss_L1_reg + loss_CE\n",
    "        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
    "        optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
    "\n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "    \n",
    "    model.eval() #model 變成測試模式\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            val_pred = model(data[0].cuda())\n",
    "            #batch_loss = loss(val_pred, data[1].cuda())\n",
    "            real_B_enc = encode_ab_ind(data[1][:, :, ::4, ::4])\n",
    "            loss_L1_reg = lossL1(val_pred.type(torch.cuda.FloatTensor), data[1].type(torch.cuda.FloatTensor).cuda())\n",
    "            loss_CE = lossCE(pred_class.type(torch.cuda.FloatTensor), real_B_enc[:, 0, :, :].type(torch.cuda.LongTensor).cuda())\n",
    "            batch_loss = loss_L1_reg + loss_CE\n",
    "            \n",
    "            if(i == 1):\n",
    "                L = data[0][6].cpu().numpy().transpose(1, 2, 0)\n",
    "                realAB = data[1][6].cpu().numpy().transpose(1, 2, 0)\n",
    "                predAB = val_pred[6].cpu().numpy().transpose(1, 2, 0)\n",
    "                realImg = (np.concatenate((L, realAB), axis=2) * 255).astype(np.uint8)\n",
    "                fakeImg = (np.concatenate((L, predAB), axis=2) * 255).astype(np.uint8)\n",
    "                # opencv 用 datatype 判斷圖片\n",
    "                realImg = cv2.cvtColor(realImg, cv2.COLOR_LAB2BGR)\n",
    "                fakeImg = cv2.cvtColor(fakeImg, cv2.COLOR_LAB2BGR) \n",
    "                #print(realImg)\n",
    "                #plt.imshow(realImg)\n",
    "                #plt.show()\n",
    "                cv2.imwrite(str(epoch + 1) + \"_real\" + \".png\"  , realImg)\n",
    "                cv2.imwrite(str(epoch + 1) + \"_fake\" + \".png\"  , fakeImg)\n",
    "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "            val_loss += batch_loss.item()\n",
    "        \n",
    "        # 只 save parameters (建議的方式)\n",
    "        torch.save(model.state_dict(), str(epoch + 1) +  \"_stage2_res_model\")\n",
    "        \n",
    "        #if val_loss < best_val_loss:\n",
    "        #    best_val_loss = val_loss\n",
    "        #    torch.save(model, \"best_model\")\n",
    "        #將結果 print 出來\n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f | time to load: %2.2f' % \\\n",
    "            (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
    "             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__(), t_data))\n",
    "        \n",
    "        train_loss_history.append(train_loss/train_set.__len__())\n",
    "        val_loss_history.append(val_loss/val_set.__len__())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
